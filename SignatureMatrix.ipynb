{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ensarkaya/CS425-Group7-TermProject/blob/master/SignatureMatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dYKunXzmaZf9",
        "colab_type": "code",
        "outputId": "7c1eacde-78cd-4d44-c54b-f0c04ab4aac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "path = '1million.csv'\n",
        "df = pd.read_csv(path)\n",
        "nltk.download('stopwords')\n",
        "dummy =[\"and\",\"or\",\"is\",\"are\",\"what\",\"where\",\"who\",\"whom\",\"when\",\"in\"\n",
        "            ,\"a\",\"an\",\"of\",\"to\",\"for\",\"from\",\"by\",\"can\",\"i\",\"with\",\"its\",\n",
        "             \"there\",\"that\",\"thats\",\"all\",\"does\",\"do\",\"did\",\"the\",\"am\",\"using\",\n",
        "             \"trying\",\"how\",\"be\",\"not\",\"doesn't\",\"don't\",\"didn't\",\"won't\",\"will\",\n",
        "             \"my\",\"be\",\"should\",\"would\",\"as\",\"use\",\"must\",\"have\",\"but\",\"however\",\"at\",\n",
        "             \"another\",\"other\",\"one\",\"two\",\"three\",\"four\",\"five\",\"still\",\"on\",\"why\",\"it\"\n",
        "              ,\"how\",\"a\",\"to\",\"'\",\".\",\",\",\";\",\":\",\"?\",\"!\",\"-\",\"_\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b3f2d8592337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1million.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m dummy =[\"and\",\"or\",\"is\",\"are\",\"what\",\"where\",\"who\",\"whom\",\"when\",\"in\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'1million.csv' does not exist: b'1million.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GyU-uln7ahhy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "randomNum={}\n",
        "for i in range(128):\n",
        "  a=random.randint(1,50000)\n",
        "  b=random.randint(1,50000)\n",
        "  randomNum[i]=(a,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0uvzBTcaw-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"title\"] = df[\"title\"].apply(lambda x: x.lower())\n",
        "stop = stopwords.words('english')\n",
        "stop.append(dummy)\n",
        "\n",
        "df[\"title\"] = df[\"title\"].str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in dummy))\n",
        "\n",
        "#keywords -> id's of questions\n",
        "dic = {}\n",
        "#questionId -> (score, answerCount, viewCount, comment_count)\n",
        "values = {}\n",
        "\n",
        "for i in range(1000000):\n",
        "  values[df.loc[i,'id']] = (df.loc[i,'title'], df.loc[i,'answer_count'], df.loc[i,'score'], df.loc[i,'view_count'], df.loc[i,'comment_count'])\n",
        "  df.loc[i,'title']\n",
        "  str = df.loc[i,'title'].split()\n",
        "  for j in range(len(str)):\n",
        "    while len(str[j]) > 0 and (str[j][0] < 'a' or str[j][0] > 'z') and (str[j][0] < '0' or str[j][0] > '9') and str[j][0] != '#' and str[j][0] != '+':\n",
        "      str[j] = str[j][1:]\n",
        "    while len(str[j]) > 0 and (str[j][len(str[j])-1] < 'a' or str[j][len(str[j])-1] > 'z') and (str[j][len(str[j])-1] < '0' or str[j][len(str[j])-1] > '9') and str[j][len(str[j])-1] != '#' and str[j][len(str[j])-1] != '+':\n",
        "      str[j] = str[j][:len(str[j])-2]\n",
        "      \n",
        "    if  str[j] != \"\":\n",
        "      if str[j] in dic:\n",
        "        dic[str[j]].append(df.loc[i,'id'])\n",
        "      else:\n",
        "        dic[str[j]]=[df.loc[i,'id']]\n",
        "# print(dic['java'][0])\n",
        "\n",
        "#keywords -> keyword count\n",
        "dic2 = {}\n",
        "#questionId -> keywords if greater than threshold\n",
        "dic3 = {}\n",
        "#array for putting index to keywords\n",
        "dic4 = {}\n",
        "#questionId -> Id's of keywords found in questions\n",
        "dic5 = {}\n",
        "#questionId -> count for keywords with count larger than threshold\n",
        "\n",
        "\n",
        "threshold = 2; \n",
        "count2=0\n",
        "for i in dic:\n",
        "#   print(i)\n",
        "  count=0\n",
        "  key = i\n",
        "  \n",
        "  for j in dic[i]:\n",
        "    count+=1\n",
        "  dic2[i]=count\n",
        "#   print(i,\" **** \", count)\n",
        "  if count > threshold:\n",
        "    for j in range(count):\n",
        "      id = dic[i][j] \n",
        "      if id in dic3:\n",
        "        dic3[id].append(i)\n",
        "      else:\n",
        "        dic3[id] = [i]\n",
        "    if key not in dic4:\n",
        "      dic4[key] = count2\n",
        "      count2+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDyPOUcYa2Mm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open(\"output.txt\", \"w\")\n",
        "for i in dic3:\n",
        "  List = []\n",
        "  for j in dic3[i]:\n",
        "    value = dic4[j]\n",
        "#     dic3[i][j] = value\n",
        "    List.append(value)\n",
        "  dic5[i] = List\n",
        "    \n",
        "for i in dic5:   \n",
        "#   print(i,\" : \",dic5[i])\n",
        "#   var = i + \" : \" + dic5[i]\n",
        "  file.write(\"%d\" % i)\n",
        "  file.write(\" : \")\n",
        "  for j in dic5[i]:\n",
        "    file.write(\"%d \" % j)\n",
        "  file.write(\"\\n\")\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpVEMNFha7dg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnt=0\n",
        "print(\"dic:\", \"end= \")\n",
        "for i in dic:\n",
        "  if cnt<5:\n",
        "    print(i,\" : \", dic[i])\n",
        "    cnt+=1\n",
        "print(\"lenght dic: \",len(dic))\n",
        "cnt=0\n",
        "print(\"dic2:\", \"end= \")\n",
        "for i in dic2:\n",
        "  if cnt<5:\n",
        "    print(i,\" : \", dic2[i])\n",
        "    cnt+=1\n",
        "print(\"lenght dic2: \",len(dic2))\n",
        "cnt=0\n",
        "print(\"dic3:\", \"end= \")\n",
        "for i in dic3:\n",
        "  if cnt<5:\n",
        "    print(i,\" : \", dic3[i])\n",
        "    cnt+=1\n",
        "print(\"lenght dic3: \",len(dic3))\n",
        "cnt=0\n",
        "print(\"dic4:\", \"end= \")\n",
        "for i in dic4:\n",
        "  if cnt<5:\n",
        "    print(i,\" : \", dic4[i])\n",
        "    cnt+=1\n",
        "print(\"lenght dic4: \",len(dic4))\n",
        "cnt=0\n",
        "print(\"dic5:\", \"end= \")\n",
        "for i in dic5:\n",
        "  if cnt<5:\n",
        "    print(i,\" : \", dic5[i])\n",
        "    cnt+=1\n",
        "print(\"lenght dic5: \",len(dic5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3v6rkhwVbEel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dicID = {}\n",
        "col=999295\n",
        "row=128\n",
        "matrix = [[0] * col for i in range(row)]\n",
        "for i in range(128):\n",
        "  count=0\n",
        "  index = 0\n",
        "  for j in dic5:\n",
        "    dicID[index] = j\n",
        "    index++\n",
        "    minSoFar=9999999\n",
        "    for k in dic5[j]:\n",
        "      hashval=(randomNum[i][0]*j + randomNum[i][1]) % 50311\n",
        "      if hashval<minSoFar:\n",
        "        minSoFar = hashval\n",
        "    matrix[i][count]=minSoFar\n",
        "    count +=1  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43hB6mLZsoEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  for j in range(100):\n",
        "    print(matrix[i][j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzRNKdE2x6Jw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file2 = open(\"signature.txt\", \"w\")\n",
        "\n",
        "for i in range(128):\n",
        "    for j in range(999295):\n",
        "      file2.write(\"%d\" % matrix[i][j])\n",
        "      file2.write(\" \")\n",
        "    file2.write(\"\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qIpwmQWjgQ8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keywords\n",
        "question = input()\n",
        "str = question.split(\" \").apply(lambda x: ' '.join(k for k in x if k not in dummy))\n",
        "for j in range(len(str)):\n",
        "  while len(str[j]) > 0 and (str[j][0] < 'a' or str[j][0] > 'z') and (str[j][0] < '0' or str[j][0] > '9') and str[j][0] != '#' and str[j][0] != '+':\n",
        "      str[j] = str[j][1:]\n",
        "  while len(str[j]) > 0 and (str[j][len(str[j])-1] < 'a' or str[j][len(str[j])-1] > 'z') and (str[j][len(str[j])-1] < '0' or str[j][len(str[j])-1] > '9') and str[j][len(str[j])-1] != '#' and str[j][len(str[j])-1] != '+':\n",
        "      str[j] = str[j][:len(str[j])-2]\n",
        "      \n",
        "if(len(str) <= 0):\n",
        "  print('Question not valid.\\n')\n",
        "else:\n",
        "    #calculating the metascore\n",
        "        \n",
        "    #min-hash of the keywords\n",
        "    index = []\n",
        "    for i in str:\n",
        "      if i in dic4:\n",
        "        index.append(dic4[i]);\n",
        "    minHash = []\n",
        "    minValue = 50311\n",
        "    for i in randomNum:\n",
        "      for j in index:\n",
        "        hashValue = (randomNum[i][0]*j + randomNum[i][1]) / 50311\n",
        "        if(hashValue < minValue):\n",
        "          minValue = hashValue\n",
        "      minHash.append[minValue]\n",
        "    \n",
        "    #locality sensitive hashing\n",
        "    candidate = []\n",
        "    r = 8\n",
        "    band = 128 / r;\n",
        "    index = 0;\n",
        "    for i in range(band)\n",
        "      str = ''\n",
        "      for j in range(r):\n",
        "        str = str + str(minHash[i*r + j])\n",
        "        hashvalue = hash(str);\n",
        "      for j in range(999295):\n",
        "        str = ''\n",
        "        for k in range(r):\n",
        "          str = str + matrix[i*r + k][j]\n",
        "          if(hash(str) = hashvalue):\n",
        "            candidate.append(dicID[j]);\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    score = 0;\n",
        "    answerCount = 0\n",
        "    viewCount = 0\n",
        "    comment_count = 0\n",
        "    for id in candidates:\n",
        "      score += values[id][3]\n",
        "      answerCount += values[id][4]\n",
        "      viewCount += values[id][5]\n",
        "      comment_count += values[id][6]\n",
        "    length = len(candidates)\n",
        "    print (\"Predicted score: \", score/length, \"\\n\")\n",
        "    print (\"Predicted number of answers: \", answercount/length, \"\\n\")\n",
        "    print (\"Predicted view count: \", viewCount/length, \"\\n\")\n",
        "    print (\"Predicted number of answers: \", comment_count/length, \"\\n\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}